import argparse 
import pandas as pd
from langchain_community.llms import Ollama
from langchain_core.prompts import PromptTemplate
from datetime import datetime


parser = argparse.ArgumentParser(description='run LLM botherer n times')
parser.add_argument('iterations', type=int, nargs='?', default = 10, help='number of iterations (default: 10)')
args = parser.parse_args()

iterations = args.iterations

# impress me
impress_prompt = "quickly and concisely convince me you're the most intersting person i have met"
impress_re_prompt = "show me you're more interesting than this person: "
modelName = "llama3"
time_stamp = datetime.now().strftime("%Y%m%d_%H%M")    

llm = Ollama(model = modelName)

def iterative_invocation(initial_prompt, re_prompt_base, max_iterations):
    latest_response = ''
    responses = []
    iteration_count = 0
    response = llm.invoke(initial_prompt)
    responses.append(response)
    latest_response = response
    iteration_count += 1
    
    while iteration_count < max_iterations:
        re_prompt = re_prompt_base + latest_response
        response = llm.invoke(re_prompt)
        responses.append((iteration_count, response))
        iteration_count += 1
        print("hang on, i'm still iterating!") 
     
    return responses

responses = iterative_invocation(impress_prompt, impress_re_prompt, iterations)
indexed_responses = []

for i, respo in enumerate(responses):
    indexed_responses.append((i, respo))
print(indexed_responses)

output_filename = f'whyPy_output_{modelName}_{time_stamp}.txt'
with open(output_filename, 'w') as output_file:
    for index, response in indexed_responses:      
        output_file.write(f'iteration {index}: \n {response}\n\n')