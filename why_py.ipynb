{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DayByDayBy/whypy/blob/main/why_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_80OOXq6d55o"
      },
      "source": [
        "#   whyPy\n",
        "---\n",
        "### a Jupyter Notebook and LLM botherer\n",
        "\n",
        "\n",
        "\n",
        "playing with iterative invocation of large language models and collecting the responses\n",
        "\n",
        "(altho right now it's just a skeleton, prep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9_HWmnKCepBP"
      },
      "outputs": [],
      "source": [
        "#@title installations\n",
        "\n",
        "# installations required to run the notebook\n",
        "\n",
        "!pip install argparse pandas sentence_transformers langchain_community langchain langchain_core datetime matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbjqAJRHfcmF"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "\n",
        "# imports to run first (some common, some less so, may be possible to skip this step depending\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from datetime import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RpSrAfh85BMH"
      },
      "outputs": [],
      "source": [
        "#@title ipy input\n",
        "\n",
        "from ipywidgets import IntText, interact\n",
        "\n",
        "iterations = IntText(value=10, description='Iterations:')\n",
        "interact(lambda iterations: iterations, iterations=iterations)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title config and setup\n",
        "\n",
        "impress_prompt = \"quickly and concisely convince me you're the most interesting person I have met\"\n",
        "impress_re_prompt = \"show me you're more interesting than this person: \"\n",
        "modelName = \"llama3\"\n",
        "time_stamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "output_filename = f'whyPy_output_{modelName}_{time_stamp}.txt'\n"
      ],
      "metadata": {
        "id": "ai9E2W6067a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title main function def\n",
        "\n",
        "%%time\n",
        "\n",
        "llm = Ollama(model=modelName)\n",
        "\n",
        "def iterative_invocation(initial_prompt, re_prompt_base, max_iterations):\n",
        "    latest_response = ''\n",
        "    responses = []\n",
        "    iteration_count = 0\n",
        "    response = llm.invoke(initial_prompt)\n",
        "    responses.append(response)\n",
        "    latest_response = response\n",
        "    iteration_count += 1\n",
        "\n",
        "    while iteration_count < max_iterations:\n",
        "        re_prompt = re_prompt_base + latest_response\n",
        "        response = llm.invoke(re_prompt)\n",
        "        responses.append((iteration_count, response))\n",
        "        iteration_count += 1\n",
        "        print(\"hang on, I'm still iterating!\")\n",
        "\n",
        "    return responses\n",
        "\n",
        "def save_responses(responses, filename):\n",
        "    with open(filename, 'w') as output_file:\n",
        "        for index, response in responses:\n",
        "            output_file.write(f'iteration {index}: \\n {response}\\n\\n')\n",
        "    print(f\"Responses saved to {filename}\")\n"
      ],
      "metadata": {
        "id": "424M_OQl2NLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title execution\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "responses = iterative_invocation(impress_prompt, impress_re_prompt, iterations.value)\n",
        "indexed_responses = [(i, respo) for i, respo in enumerate(responses)]\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Total execution time: {execution_time} seconds\")\n",
        "\n",
        "save_responses(indexed_responses, output_filename)\n"
      ],
      "metadata": {
        "id": "sokAdOef7RWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe and display\n",
        "\n",
        "indexed_responses_df = pd.DataFrame(indexed_responses, columns=['Iteration', 'Response'])\n",
        "display(indexed_responses_df)\n"
      ],
      "metadata": {
        "id": "5k9wfjRA7d6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XbiqLyci7dYO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPELV42E5hQ31A+SSpHcnqT",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
